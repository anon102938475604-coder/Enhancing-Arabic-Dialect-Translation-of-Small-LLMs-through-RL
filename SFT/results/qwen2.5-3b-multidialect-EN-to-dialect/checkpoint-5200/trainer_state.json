{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 5200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.019230769230769232,
      "grad_norm": 2.4916555881500244,
      "learning_rate": 4.952884615384615e-05,
      "loss": 2.4675,
      "step": 50
    },
    {
      "epoch": 0.038461538461538464,
      "grad_norm": 2.566469430923462,
      "learning_rate": 4.9048076923076926e-05,
      "loss": 2.2877,
      "step": 100
    },
    {
      "epoch": 0.057692307692307696,
      "grad_norm": 3.177579402923584,
      "learning_rate": 4.856730769230769e-05,
      "loss": 2.1189,
      "step": 150
    },
    {
      "epoch": 0.07692307692307693,
      "grad_norm": 3.8441832065582275,
      "learning_rate": 4.8086538461538466e-05,
      "loss": 2.0347,
      "step": 200
    },
    {
      "epoch": 0.09615384615384616,
      "grad_norm": 4.236324310302734,
      "learning_rate": 4.760576923076923e-05,
      "loss": 1.9364,
      "step": 250
    },
    {
      "epoch": 0.11538461538461539,
      "grad_norm": 4.582733154296875,
      "learning_rate": 4.7125e-05,
      "loss": 1.8953,
      "step": 300
    },
    {
      "epoch": 0.1346153846153846,
      "grad_norm": 5.088973522186279,
      "learning_rate": 4.6644230769230774e-05,
      "loss": 1.8239,
      "step": 350
    },
    {
      "epoch": 0.15384615384615385,
      "grad_norm": 4.709386348724365,
      "learning_rate": 4.616346153846154e-05,
      "loss": 1.8175,
      "step": 400
    },
    {
      "epoch": 0.17307692307692307,
      "grad_norm": 5.536274433135986,
      "learning_rate": 4.568269230769231e-05,
      "loss": 1.7822,
      "step": 450
    },
    {
      "epoch": 0.19230769230769232,
      "grad_norm": 5.19740104675293,
      "learning_rate": 4.520192307692308e-05,
      "loss": 1.7518,
      "step": 500
    },
    {
      "epoch": 0.21153846153846154,
      "grad_norm": 5.134446620941162,
      "learning_rate": 4.472115384615385e-05,
      "loss": 1.7223,
      "step": 550
    },
    {
      "epoch": 0.23076923076923078,
      "grad_norm": 5.1221160888671875,
      "learning_rate": 4.4240384615384615e-05,
      "loss": 1.7268,
      "step": 600
    },
    {
      "epoch": 0.25,
      "grad_norm": 6.110909461975098,
      "learning_rate": 4.375961538461539e-05,
      "loss": 1.6296,
      "step": 650
    },
    {
      "epoch": 0.2692307692307692,
      "grad_norm": 5.738921642303467,
      "learning_rate": 4.3278846153846156e-05,
      "loss": 1.6532,
      "step": 700
    },
    {
      "epoch": 0.28846153846153844,
      "grad_norm": 5.63926887512207,
      "learning_rate": 4.279807692307692e-05,
      "loss": 1.6067,
      "step": 750
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 5.79737663269043,
      "learning_rate": 4.23173076923077e-05,
      "loss": 1.6227,
      "step": 800
    },
    {
      "epoch": 0.3269230769230769,
      "grad_norm": 6.142545700073242,
      "learning_rate": 4.1836538461538464e-05,
      "loss": 1.5844,
      "step": 850
    },
    {
      "epoch": 0.34615384615384615,
      "grad_norm": 6.414444446563721,
      "learning_rate": 4.135576923076923e-05,
      "loss": 1.5327,
      "step": 900
    },
    {
      "epoch": 0.36538461538461536,
      "grad_norm": 5.565051078796387,
      "learning_rate": 4.0875000000000004e-05,
      "loss": 1.6025,
      "step": 950
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 6.891846179962158,
      "learning_rate": 4.039423076923077e-05,
      "loss": 1.484,
      "step": 1000
    },
    {
      "epoch": 0.40384615384615385,
      "grad_norm": 5.899792671203613,
      "learning_rate": 3.991346153846154e-05,
      "loss": 1.5053,
      "step": 1050
    },
    {
      "epoch": 0.4230769230769231,
      "grad_norm": 5.356434345245361,
      "learning_rate": 3.943269230769231e-05,
      "loss": 1.5681,
      "step": 1100
    },
    {
      "epoch": 0.4423076923076923,
      "grad_norm": 5.8810248374938965,
      "learning_rate": 3.895192307692308e-05,
      "loss": 1.4885,
      "step": 1150
    },
    {
      "epoch": 0.46153846153846156,
      "grad_norm": 6.0506486892700195,
      "learning_rate": 3.8471153846153846e-05,
      "loss": 1.462,
      "step": 1200
    },
    {
      "epoch": 0.4807692307692308,
      "grad_norm": 6.4063286781311035,
      "learning_rate": 3.799038461538462e-05,
      "loss": 1.4685,
      "step": 1250
    },
    {
      "epoch": 0.5,
      "grad_norm": 6.358665466308594,
      "learning_rate": 3.7509615384615386e-05,
      "loss": 1.4987,
      "step": 1300
    },
    {
      "epoch": 0.5192307692307693,
      "grad_norm": 7.529792308807373,
      "learning_rate": 3.702884615384615e-05,
      "loss": 1.4604,
      "step": 1350
    },
    {
      "epoch": 0.5384615384615384,
      "grad_norm": 6.703788757324219,
      "learning_rate": 3.654807692307693e-05,
      "loss": 1.45,
      "step": 1400
    },
    {
      "epoch": 0.5576923076923077,
      "grad_norm": 5.958035945892334,
      "learning_rate": 3.6067307692307694e-05,
      "loss": 1.4318,
      "step": 1450
    },
    {
      "epoch": 0.5769230769230769,
      "grad_norm": 5.631986618041992,
      "learning_rate": 3.558653846153847e-05,
      "loss": 1.4044,
      "step": 1500
    },
    {
      "epoch": 0.5961538461538461,
      "grad_norm": 6.292647361755371,
      "learning_rate": 3.510576923076923e-05,
      "loss": 1.4138,
      "step": 1550
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 7.342890739440918,
      "learning_rate": 3.4625e-05,
      "loss": 1.3629,
      "step": 1600
    },
    {
      "epoch": 0.6346153846153846,
      "grad_norm": 6.5284037590026855,
      "learning_rate": 3.4144230769230775e-05,
      "loss": 1.3667,
      "step": 1650
    },
    {
      "epoch": 0.6538461538461539,
      "grad_norm": 5.90830659866333,
      "learning_rate": 3.3663461538461535e-05,
      "loss": 1.4014,
      "step": 1700
    },
    {
      "epoch": 0.6730769230769231,
      "grad_norm": 5.8674139976501465,
      "learning_rate": 3.318269230769231e-05,
      "loss": 1.3859,
      "step": 1750
    },
    {
      "epoch": 0.6923076923076923,
      "grad_norm": 5.928843975067139,
      "learning_rate": 3.270192307692308e-05,
      "loss": 1.3435,
      "step": 1800
    },
    {
      "epoch": 0.7115384615384616,
      "grad_norm": 6.379510402679443,
      "learning_rate": 3.222115384615384e-05,
      "loss": 1.462,
      "step": 1850
    },
    {
      "epoch": 0.7307692307692307,
      "grad_norm": 5.64563512802124,
      "learning_rate": 3.1740384615384616e-05,
      "loss": 1.3609,
      "step": 1900
    },
    {
      "epoch": 0.75,
      "grad_norm": 6.526845455169678,
      "learning_rate": 3.125961538461539e-05,
      "loss": 1.3539,
      "step": 1950
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 6.777388572692871,
      "learning_rate": 3.077884615384615e-05,
      "loss": 1.3686,
      "step": 2000
    },
    {
      "epoch": 0.7884615384615384,
      "grad_norm": 6.198419570922852,
      "learning_rate": 3.0298076923076924e-05,
      "loss": 1.3408,
      "step": 2050
    },
    {
      "epoch": 0.8076923076923077,
      "grad_norm": 6.276008605957031,
      "learning_rate": 2.9817307692307694e-05,
      "loss": 1.3776,
      "step": 2100
    },
    {
      "epoch": 0.8269230769230769,
      "grad_norm": 6.6176252365112305,
      "learning_rate": 2.9336538461538465e-05,
      "loss": 1.3263,
      "step": 2150
    },
    {
      "epoch": 0.8461538461538461,
      "grad_norm": 7.142397880554199,
      "learning_rate": 2.885576923076923e-05,
      "loss": 1.364,
      "step": 2200
    },
    {
      "epoch": 0.8653846153846154,
      "grad_norm": 6.9571003913879395,
      "learning_rate": 2.8375000000000002e-05,
      "loss": 1.362,
      "step": 2250
    },
    {
      "epoch": 0.8846153846153846,
      "grad_norm": 6.761955738067627,
      "learning_rate": 2.7894230769230772e-05,
      "loss": 1.3558,
      "step": 2300
    },
    {
      "epoch": 0.9038461538461539,
      "grad_norm": 6.169005393981934,
      "learning_rate": 2.741346153846154e-05,
      "loss": 1.3307,
      "step": 2350
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 6.4384355545043945,
      "learning_rate": 2.693269230769231e-05,
      "loss": 1.3355,
      "step": 2400
    },
    {
      "epoch": 0.9423076923076923,
      "grad_norm": 7.578139781951904,
      "learning_rate": 2.645192307692308e-05,
      "loss": 1.3407,
      "step": 2450
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 6.687037467956543,
      "learning_rate": 2.5971153846153847e-05,
      "loss": 1.3022,
      "step": 2500
    },
    {
      "epoch": 0.9807692307692307,
      "grad_norm": 7.331318378448486,
      "learning_rate": 2.5490384615384617e-05,
      "loss": 1.2608,
      "step": 2550
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.930165767669678,
      "learning_rate": 2.5009615384615387e-05,
      "loss": 1.34,
      "step": 2600
    },
    {
      "epoch": 1.0192307692307692,
      "grad_norm": 6.567285537719727,
      "learning_rate": 2.4528846153846154e-05,
      "loss": 1.1689,
      "step": 2650
    },
    {
      "epoch": 1.0384615384615385,
      "grad_norm": 6.737666130065918,
      "learning_rate": 2.4048076923076925e-05,
      "loss": 1.1303,
      "step": 2700
    },
    {
      "epoch": 1.0576923076923077,
      "grad_norm": 7.1057257652282715,
      "learning_rate": 2.3567307692307695e-05,
      "loss": 1.1751,
      "step": 2750
    },
    {
      "epoch": 1.0769230769230769,
      "grad_norm": 7.747491836547852,
      "learning_rate": 2.3086538461538462e-05,
      "loss": 1.1841,
      "step": 2800
    },
    {
      "epoch": 1.0961538461538463,
      "grad_norm": 6.587740898132324,
      "learning_rate": 2.2605769230769232e-05,
      "loss": 1.1629,
      "step": 2850
    },
    {
      "epoch": 1.1153846153846154,
      "grad_norm": 8.436910629272461,
      "learning_rate": 2.2125000000000002e-05,
      "loss": 1.1273,
      "step": 2900
    },
    {
      "epoch": 1.1346153846153846,
      "grad_norm": 7.049140453338623,
      "learning_rate": 2.164423076923077e-05,
      "loss": 1.1063,
      "step": 2950
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 6.280869960784912,
      "learning_rate": 2.116346153846154e-05,
      "loss": 1.106,
      "step": 3000
    },
    {
      "epoch": 1.1730769230769231,
      "grad_norm": 7.876911163330078,
      "learning_rate": 2.068269230769231e-05,
      "loss": 1.1121,
      "step": 3050
    },
    {
      "epoch": 1.1923076923076923,
      "grad_norm": 7.398066520690918,
      "learning_rate": 2.0201923076923077e-05,
      "loss": 1.1115,
      "step": 3100
    },
    {
      "epoch": 1.2115384615384615,
      "grad_norm": 7.090379238128662,
      "learning_rate": 1.9721153846153847e-05,
      "loss": 1.1418,
      "step": 3150
    },
    {
      "epoch": 1.2307692307692308,
      "grad_norm": 7.570849418640137,
      "learning_rate": 1.9240384615384614e-05,
      "loss": 1.1386,
      "step": 3200
    },
    {
      "epoch": 1.25,
      "grad_norm": 6.539637565612793,
      "learning_rate": 1.8759615384615388e-05,
      "loss": 1.1177,
      "step": 3250
    },
    {
      "epoch": 1.2692307692307692,
      "grad_norm": 7.914483547210693,
      "learning_rate": 1.8278846153846155e-05,
      "loss": 1.0921,
      "step": 3300
    },
    {
      "epoch": 1.2884615384615383,
      "grad_norm": 6.210967063903809,
      "learning_rate": 1.7798076923076922e-05,
      "loss": 1.1359,
      "step": 3350
    },
    {
      "epoch": 1.3076923076923077,
      "grad_norm": 7.753411293029785,
      "learning_rate": 1.7317307692307695e-05,
      "loss": 1.1242,
      "step": 3400
    },
    {
      "epoch": 1.3269230769230769,
      "grad_norm": 6.944093704223633,
      "learning_rate": 1.6836538461538462e-05,
      "loss": 1.1176,
      "step": 3450
    },
    {
      "epoch": 1.3461538461538463,
      "grad_norm": 7.873185634613037,
      "learning_rate": 1.6355769230769233e-05,
      "loss": 1.135,
      "step": 3500
    },
    {
      "epoch": 1.3653846153846154,
      "grad_norm": 6.965263366699219,
      "learning_rate": 1.5875e-05,
      "loss": 1.1436,
      "step": 3550
    },
    {
      "epoch": 1.3846153846153846,
      "grad_norm": 6.738004684448242,
      "learning_rate": 1.539423076923077e-05,
      "loss": 1.0837,
      "step": 3600
    },
    {
      "epoch": 1.4038461538461537,
      "grad_norm": 7.379415988922119,
      "learning_rate": 1.491346153846154e-05,
      "loss": 1.1071,
      "step": 3650
    },
    {
      "epoch": 1.4230769230769231,
      "grad_norm": 6.77752161026001,
      "learning_rate": 1.4432692307692309e-05,
      "loss": 1.0621,
      "step": 3700
    },
    {
      "epoch": 1.4423076923076923,
      "grad_norm": 8.216734886169434,
      "learning_rate": 1.3951923076923076e-05,
      "loss": 1.1029,
      "step": 3750
    },
    {
      "epoch": 1.4615384615384617,
      "grad_norm": 7.208953380584717,
      "learning_rate": 1.3471153846153848e-05,
      "loss": 1.0878,
      "step": 3800
    },
    {
      "epoch": 1.4807692307692308,
      "grad_norm": 7.050089359283447,
      "learning_rate": 1.2990384615384615e-05,
      "loss": 1.0929,
      "step": 3850
    },
    {
      "epoch": 1.5,
      "grad_norm": 7.640536785125732,
      "learning_rate": 1.2509615384615387e-05,
      "loss": 1.1164,
      "step": 3900
    },
    {
      "epoch": 1.5192307692307692,
      "grad_norm": 6.925807476043701,
      "learning_rate": 1.2028846153846154e-05,
      "loss": 1.076,
      "step": 3950
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 8.370159149169922,
      "learning_rate": 1.1548076923076924e-05,
      "loss": 1.0919,
      "step": 4000
    },
    {
      "epoch": 1.5576923076923077,
      "grad_norm": 7.460559844970703,
      "learning_rate": 1.1067307692307694e-05,
      "loss": 1.059,
      "step": 4050
    },
    {
      "epoch": 1.5769230769230769,
      "grad_norm": 7.37370491027832,
      "learning_rate": 1.0586538461538461e-05,
      "loss": 1.0993,
      "step": 4100
    },
    {
      "epoch": 1.5961538461538463,
      "grad_norm": 6.185410976409912,
      "learning_rate": 1.0105769230769232e-05,
      "loss": 1.1291,
      "step": 4150
    },
    {
      "epoch": 1.6153846153846154,
      "grad_norm": 7.721086502075195,
      "learning_rate": 9.625e-06,
      "loss": 1.09,
      "step": 4200
    },
    {
      "epoch": 1.6346153846153846,
      "grad_norm": 6.9747819900512695,
      "learning_rate": 9.14423076923077e-06,
      "loss": 1.0848,
      "step": 4250
    },
    {
      "epoch": 1.6538461538461537,
      "grad_norm": 6.993859767913818,
      "learning_rate": 8.663461538461539e-06,
      "loss": 1.0693,
      "step": 4300
    },
    {
      "epoch": 1.6730769230769231,
      "grad_norm": 8.369603157043457,
      "learning_rate": 8.182692307692308e-06,
      "loss": 1.0734,
      "step": 4350
    },
    {
      "epoch": 1.6923076923076923,
      "grad_norm": 8.9290132522583,
      "learning_rate": 7.701923076923078e-06,
      "loss": 1.0538,
      "step": 4400
    },
    {
      "epoch": 1.7115384615384617,
      "grad_norm": 7.091592311859131,
      "learning_rate": 7.221153846153847e-06,
      "loss": 1.0543,
      "step": 4450
    },
    {
      "epoch": 1.7307692307692308,
      "grad_norm": 7.493896484375,
      "learning_rate": 6.740384615384615e-06,
      "loss": 1.0428,
      "step": 4500
    },
    {
      "epoch": 1.75,
      "grad_norm": 7.640501499176025,
      "learning_rate": 6.259615384615385e-06,
      "loss": 1.0436,
      "step": 4550
    },
    {
      "epoch": 1.7692307692307692,
      "grad_norm": 6.616527557373047,
      "learning_rate": 5.778846153846154e-06,
      "loss": 1.0614,
      "step": 4600
    },
    {
      "epoch": 1.7884615384615383,
      "grad_norm": 7.582612037658691,
      "learning_rate": 5.298076923076924e-06,
      "loss": 1.0747,
      "step": 4650
    },
    {
      "epoch": 1.8076923076923077,
      "grad_norm": 7.426311492919922,
      "learning_rate": 4.817307692307692e-06,
      "loss": 1.0911,
      "step": 4700
    },
    {
      "epoch": 1.8269230769230769,
      "grad_norm": 6.26939058303833,
      "learning_rate": 4.336538461538462e-06,
      "loss": 1.0747,
      "step": 4750
    },
    {
      "epoch": 1.8461538461538463,
      "grad_norm": 7.104660987854004,
      "learning_rate": 3.855769230769231e-06,
      "loss": 1.0629,
      "step": 4800
    },
    {
      "epoch": 1.8653846153846154,
      "grad_norm": 5.835111141204834,
      "learning_rate": 3.3750000000000003e-06,
      "loss": 1.0224,
      "step": 4850
    },
    {
      "epoch": 1.8846153846153846,
      "grad_norm": 7.111189365386963,
      "learning_rate": 2.8942307692307693e-06,
      "loss": 1.0655,
      "step": 4900
    },
    {
      "epoch": 1.9038461538461537,
      "grad_norm": 7.945703029632568,
      "learning_rate": 2.413461538461539e-06,
      "loss": 1.0556,
      "step": 4950
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 8.277776718139648,
      "learning_rate": 1.932692307692308e-06,
      "loss": 1.0679,
      "step": 5000
    },
    {
      "epoch": 1.9423076923076923,
      "grad_norm": 7.7432861328125,
      "learning_rate": 1.451923076923077e-06,
      "loss": 1.0279,
      "step": 5050
    },
    {
      "epoch": 1.9615384615384617,
      "grad_norm": 8.140028953552246,
      "learning_rate": 9.711538461538462e-07,
      "loss": 1.0774,
      "step": 5100
    },
    {
      "epoch": 1.9807692307692308,
      "grad_norm": 6.970433712005615,
      "learning_rate": 4.903846153846154e-07,
      "loss": 1.0868,
      "step": 5150
    },
    {
      "epoch": 2.0,
      "grad_norm": 7.837013244628906,
      "learning_rate": 9.615384615384615e-09,
      "loss": 1.0437,
      "step": 5200
    }
  ],
  "logging_steps": 50,
  "max_steps": 5200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.065860114389402e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
